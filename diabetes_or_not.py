# -*- coding: utf-8 -*-
"""Diabetes_Or_Not.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1igbVNM1JwnA8mCaI_aRJOrrcdtcV2OPd
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

"""Data collection and analysis
PIMA Diabates Dataset
> Add blockquote

1 represent the paitent is diabatic and 0 represent the paitent is non diabatic
"""

# loading the diabates dataset to a pandas Dataframe
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

pd.read_csv?

# it will print first five row of the data set
diabetes_dataset.head()

# number of rows and columns in this dataset
diabetes_dataset.shape

# getting the statistical measure of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()

"""500 person jisko diabets nhi hai
268 person jisko diabetes hai
this is nothig but the find the count of the person to whoom (jisko) diabetes hai or jisko diabetes nhi hai
"""

diabetes_dataset.groupby('Outcome').mean()

"""it will provide the mean value  or average value of all the parameter i.e pregnancies, glucose, bloodpressure etc...
0 menas jinko diabetes nhi hai unka mean or aerage value hai
1 menas jinko diabatetes hai unka mean or average value hai
jisko diabetes hai uska mean or average value jayda hoga
"""

X = diabetes_dataset.drop(columns = 'Outcome', axis=1)
Y = diabetes_dataset['Outcome']

"""if we are using drop function we have to specify the axis 1 if you are droping the column if you are dropting the row then you need to spacify the axis = 0
now we are storing all the lebel in variable Y
"""

print(X)

print(Y)

"""Data Standardization"""

scaler = StandardScaler()

scaler.fit(X)

standardized_data = scaler.transform(X)

print(standardized_data)

"""Now all the value is in similar range now this technique will help ML model for better prediction
previous one is veri different in range that's why we will do in similar range  and 1 all the value is in between  and 1
"""

X = standardized_data
Y = diabetes_dataset['Outcome']

"""we just copy standardzied data into X variable and we copy all lebels in Y variable , Y is used for training a machine learning model (X represent tha data and Y represent the model)"""

print(X)
print(Y)

"""Our model is tranined is on 768 example

Train test Split
"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)

"""it is basically split the data or replicate the code,
#train_test_split: This is a function from the sklearn.model_selection module in scikit-learn. It's used to split datasets into random train and test subsets.

#test_size = 0.2: This parameter specifies the proportion of the dataset to include in the test split. Here, it's set to 0.2, meaning 20% of the data will be used for testing, and the rest (80%) will be used for training.

#stratify=Y: This parameter ensures that the splitting process is done in a way that preserves the proportion of samples in each class of the target variable Y. This is particularly useful for imbalanced datasets where one class may be significantly more prevalent than others. By stratifying, you ensure that both the training and testing sets have a similar class distribution.

#random_state=2: This parameter sets the random seed for reproducibility. Setting a random seed ensures that the random splitting process will produce the same results each time you run the code, which is important for reproducible research and consistent results.

#The line of code essentially splits your dataset (X and Y) into four parts: X_train, X_test, Y_train, and Y_test, with 80% of the data used for training (X_train and Y_train) and 20% for testing (X_test and Y_test)
"""

print(X.shape, X_train.shape, X_test.shape)

"""768 data is the example of original data set
and outof 614 is going to used traning data set and 154 will be our test data

Training the model
"""

classifier = svm.SVC(kernel ='linear')

"""we will create the classifier variable where we can store trained data svm is used to support vector machine and support vector classifier svm and svc
we are going to use linear model that's why we put linear now this will load the (svm) model into this variable classifier and now we will fir traning data into this classifier
"""

#training the suppoer vector machine classifier
classifier.fit(X_train, Y_train)

"""this will train our machine learning model
this represent traning data and lebel for traning data this is very small dataset for training the model if you making large amount of ML model then you can put large amount of traning dataset classifier me x ka and Y ka data ko tranied ker ke daal diye

### **Model Evaluation**

Now we can evaluate our model evaluation is check how many times our models is predecting correctly
"""

#accuracy score on the traning data
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

"""This is basically predeict the lebel for all the extreme we are stoing all the lebels in this extreme prediction variable .. Now we are comparing the prediction of our model which is store in the extrem prediciton with the original labels that is Y train accuracy wala line comare karega"""

print('Accuracy score of the traning data : ', training_data_accuracy)

"""Now we are printing accuracy score of traned data and original labels that is Y it is 0.78 menas almost 0.78 means 0.79 so it means our 79 times our machine leaning model predict correctly"""

#accuracy score on the test data
X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

"""same thing in upper side we have checked for traning data accuracy now we will check test data accuracy we have to check both accuracy traning data and test data"""

print('Accuracy score of the test data :', test_data_accuracy)

"""0.78 for traning data and 0.77 for test data it is good

CREATE PREDICTING SYSTEM
now in this the Machine leaning model will predict whether the paitent have diabetes or not
"""

input_data =(6,148,72,35,0,33.6,0.627,50)
# chaning the input list into numpy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardized the input data
std_data = scaler.transform(input_data_reshaped)
print(std_data)

prediction = classifier.predict(std_data)
print(prediction)

if (prediction[0] == 0):
      print('The person is not Diabetic')
else:
      print('The person is Diabetic')

"""first of all we have changed input list into numpy aaray then we will do reshaped

We will do reshape because we are not giving ML model to 768 example but we are just trying to predict the label for only one instance means ek (1,97,66,15,140,23.2,0.487,22) ye raha ek instance aaisa aaisa bohot log aayenge ye ek aadmi ka instance hai isliye hmlog reshaped kerte hai

then we will standardized the data we can not give this value into the model because while traning our model we have to standardized the data so we have not use raw data as such if we give this data then our model can not make predictions correctly that's why we will give standardized data to the model
jaise traning data ko standardized kiye the waise hi isko bhi standardized karenge ... scaler me hmlog X ka data ko standardized kiye the to waise hi scaler.transform(input_data_reshaped) ko bhi standardized ker denge scaler.transform() is used to standardized the data

ab is standardized ka use ker ke  predicit karenge
prediction naam ka variable banayenge

classifire is tranined support vector machine learning model of X and Y ....classifier me hamlog model ko tranined ker ke dal diye the ab usko prediction me use karenge
classifier.predict(std_data) .predict function ka use karenge usme  standard data daal denge classifier me tranined data tha

prediction[0] means hmlog ko ek hi value chahiye jo ki first position mr hoga isliye index[0] ks use karenge

SAVING THE TRANINED MODEL
"""

import pickle

"""tranined model is the file name which we saving in filename variable , ek file banayenge file name ka usme classifier me model store the dibetes ka usko save karenge pickle.dump use ker ke (wb) means it is in binary format that's why wb = write binary"""

filename = 'trained_model.sav'
pickle.dump(classifier, open(filename, 'wb'))

#loading the saved model
loaded_model = pickle.load(open('trained_model.sav', 'rb'))

"""create a loaded_model variable and load the model which are saved in the filename variable , by using pickle.load() function , put open(trained model.sav ) means put file into this funciton in rb = read binary"""



input_data =(6,148,72,35,0,33.6,0.627,50)
# chaning the input list into numpy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

#standardized the input data
std_data = scaler.transform(input_data_reshaped)
print(std_data)

prediction = loaded_model.predict(std_data)
print(prediction)

if (prediction[0] == 0):
      print('The person is not Diabetic')
else:
      print('The person is Diabetic')

"""copied the input code or driver code and just change loaded_model.prediction(input_data_reshaped) inseated of classifier"""

print(X.shape)